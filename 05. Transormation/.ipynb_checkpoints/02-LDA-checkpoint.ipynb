{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA\n",
    "Линейный дискриминантный анализ (linear discriminant analysis, LDA), он же канонический, может использоваться в качестве методов для выделения признаков в целях увеличения вычислительной эффективности и уменьшения степени переобучения из-за проблемы проклятия размерности в нерегуляризованных моделях.\n",
    "\n",
    "Ключевые шаги алгоритма:\n",
    "1. стандартизировать $d$-менрный набор данных;\n",
    "2. для каждого класса вычислить $d$-мерный вектор средних;\n",
    "3. создать матрицу разброса между классами $S_B$ и матрицу разбросов внутри класса $S_W$;\n",
    "4. вычислить собственные векторы и собственные значения $S_W^{-1}S_B$;\n",
    "5. выбрать $k$ собственных векторов, которые соответствуют $k$ самым большим собственным значениям для построения $d \\times k$-матрицы преобразования $W$; собственные векторы являются столбцами этой матрицы;\n",
    "6. спроецировать образцы на новое подпространство признаков при помощи матрицы преобразования $W$.\n",
    "\n",
    "При использовании LDA мы делаем допущение, что признаки нормально распределены и независиы друг от друга.\n",
    "\n",
    "Для построения матриц разброса вычислим вектора средних значений признаков\n",
    "$$ m_i = \\frac{1}{n_i}\\sum_{x \\in D_i}^c x_m $$\n",
    "где каждый вектор $m_i$ хранит среднее значение $\\mu_m$ отностильено образцов класса $i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/wine/wine.data', header=None)\n",
    "\n",
    "X, y = df.iloc[:, 1:].values, df.iloc[:, 0].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=0)\n",
    "sc = StandardScaler()\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bектор средних класса 1:\n",
      " [ 0.9259 -0.3091  0.2592 -0.7989  0.3039  0.9608  1.0515 -0.6306  0.5354\n",
      "  0.2209  0.4855  0.798   1.2017]\n",
      "\n",
      "Bектор средних класса 2:\n",
      " [-0.8727 -0.3854 -0.4437  0.2481 -0.2409 -0.1059  0.0187 -0.0164  0.1095\n",
      " -0.8796  0.4392  0.2776 -0.7016]\n",
      "\n",
      "Bектор средних класса 3:\n",
      " [ 0.1637  0.8929  0.3249  0.5658 -0.01   -0.9499 -1.228   0.7436 -0.7652\n",
      "  0.979  -1.1698 -1.3007 -0.3912]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=4)\n",
    "mean_vecs = []\n",
    "for label in range(1, 4):\n",
    "    mean_vecs.append(np.mean(X_train_std[y_train==label], axis=0))\n",
    "    print('Bектор средних класса {0}:\\n {1}\\n'.format(label, mean_vecs[label - 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, используя вектора средних, можно вычислить матрицу разброса точек внутри класса $S_W$\n",
    "$$ S_W =  \\sum_{i=1}^c S_i $$\n",
    "Она вычисляется путем суммирования индивидуальных матриц разброса $S_i$, каждого индивидуального класса $i$\n",
    "$$ S_i = \\sum_{x \\in D_i} (x - m_i) (x - m_i)^T $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Внутриклассовая матрица разброса: 13x13\n"
     ]
    }
   ],
   "source": [
    "d = 13 # feature count\n",
    "S_W = np.zeros((d, d))\n",
    "for label, mv in zip(range(1, 4), mean_vecs):\n",
    "    class_scatter = np.zeros((d, d))\n",
    "    for row in X_train_std[y_train==label]:\n",
    "        row, mv = row.reshape(d, 1), mv.reshape(d, 1)\n",
    "        class_scatter += (row - mv).dot((row - mv).T)\n",
    "    S_W += class_scatter\n",
    "print('Внутриклассовая матрица разброса: {0}x{1}'.format(S_W.shape[0], S_W.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Во время вычисления матрицы разброса, мы допускаем что метки классов в тренировочном наборе распределены равномерно, но это не так. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Распределение меток классов: [40 49 35]\n"
     ]
    }
   ],
   "source": [
    "print('Распределение меток классов: {}'.format(np.bincount(y_train)[1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно заметить, что вычисление матрицы расброса фактически не отличается от вычисления ковариационной матрицы. Ковариационная матрица - нормализованная версия матрицы разброса.\n",
    "$$ \\Sigma_i = \\frac{1}{N_i}S_W = \\frac{1}{N_i}\\sum_{x \\in D_i}^c (x - m_i) (x - m_i)^T $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Маштабированная внутриклассовая матрица разброса: 13x13\n"
     ]
    }
   ],
   "source": [
    "d = 13 # feature count\n",
    "S_W = np.zeros((d, d))\n",
    "for label, mv in zip(range(1, 4), mean_vecs):\n",
    "    class_scatter = np.cov(X_train_std[y_train==label].T)\n",
    "    S_W += class_scatter\n",
    "print('Маштабированная внутриклассовая матрица разброса: {0}x{1}'.format(S_W.shape[0], S_W.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующий шаг вычисление матрица разброса между классами\n",
    "$$ S_B = \\sum_{i=1}^c N_i (m_i - m) (m_i - m)^T$$\n",
    "здесь $m$ - общее среднее, вклчающее в себя образцы из всех классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_overall = np.mean(X_train_std, axis=0)\n",
    "d = 13\n",
    "S_B = np.zeros((d, d))\n",
    "for i, mean_vec in enumerate(mean_vecs):\n",
    "    n = X_train[y_train == i + 1, :].shape[0]\n",
    "    mean_vec = mean_vec.reshape(d, 1)\n",
    "    mean_overall = mean_overall.reshape(d, 1)\n",
    "    S_B += n * (mean_vec - mean_overall).dot((mean_vec - mean_overall).T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Собственные векторы\n",
      "452.721581245\n",
      "156.43636122\n",
      "8.37963116479e-14\n",
      "3.37938173702e-14\n",
      "3.37938173702e-14\n",
      "2.84217094304e-14\n",
      "2.36753724288e-14\n",
      "1.48487560517e-14\n",
      "1.48487560517e-14\n",
      "1.442402744e-14\n",
      "1.442402744e-14\n",
      "1.80266604142e-15\n",
      "1.80266604142e-15\n"
     ]
    }
   ],
   "source": [
    "eigen_vals, eigen_vecs = np.linalg.eig(np.linalg.inv(S_W).dot(S_B))\n",
    "eigen_pars = [(np.abs(eigen_vals[i]), eigen_vecs[i])\n",
    "              for i in range(len(eigen_vals))]\n",
    "eigen_pars = sorted(eigen_pars, \n",
    "                    key=lambda x: x[0], reverse=True)\n",
    "print('Собственные векторы')\n",
    "for eigen_val in eigen_pars:\n",
    "    print(eigen_val[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В LDA число линейных компонентов не превышает $c - 1$, где $c$ число меток классов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
